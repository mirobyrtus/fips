
This readme file explains how to build and run the 2 parts of the project, 
CPP and Unity part.

############################################################################
#### CPP Part                                                           ####
############################################################################
 
This Part is based on FaceTracker from Jason Saragih (http://jsaragih.org/). 
Please see the license.md and readme.md files.
 
----------------------------------------------------------------------------
 
Requirements - Windows:

+ CMake 2.8. or higher
	* http://www.cmake.org/

+ OpenCV 2.4.9. or higher (The Project was developed and tested with the version 2.4.9.)
	* http://opencv.org/

+ Microsoft Visual Studio 2013 (There are additional settings needed in the version 2010)
	* It's not recommended to use the "ARM" or "Win64" version of the generator in the 
	  CMake compilers list.
	
Requirements - OSX: 

+ CMake 2.8. or higher
	* http://www.cmake.org/

+ OpenCV 2.4.9. or higher (The Project was developed and tested with the version 2.4.9.)
	* http://opencv.org/

+ XCode 6.X or higher
	* https://developer.apple.com/xcode/

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

The CPP part is used for both training and fitting the model.

Note: It is recommended to build the CPP part with Cmake into the "build" directory, 
so that the models will be found on their default place. Otherwise, you have to set 
the paths via run parameters as following:
	-m <string> -> Tracker model (default: ../model/face2.tracker)
	-c <string> -> Connectivity (default: ../model/face.con)
	-t <string> -> Triangulation (default: ../model/face.tri)

:: Training :: 

Info - The main method can be found in the "plugin.cpp" file in the "FACE_TRACKER" project. 

To make it run, you will need to copy the "model/face2.tracker" into the root 
directory of the generated solution. After that you should be able to run the 
project "FACE_TRACKER" without any run-parameters. 

How to train:
You can train the model by pressing following keys:
	'n' to train neutral face
	'h' to train happy face
	's' to train sad face
	'f' to train fear face
	'a' to train anger face
	'u' to train surprise face
	'g' to train disgust face
Emotions will be processed accordingly to your emotion captured by the webcam at the moment
you hit the key.

To train and save the model, hit the 't' key. The trained model will be saved in the 
"trained_svm.yml" file in the root directory of the project. This file will be needed 
in the Unity project. (One prepared "trained_svm.yml" file will be delivered in the Unity 
project, to make the testing easier)

----------------------------------------------------------------------------

:: Fitting ::

Fitting will be done on the Unity side. From the FACE_TRACKER project we will need 
to prepare the dynamic library for the Unity part (.dll for Windows or .bundle for OSX).

For this purpose you will have to set up in your project as following:

! Watch up, with the following setting you won't be able to run the training part !
  I recommend to set this for the "Release" mode only, so that you will be able to 
  train your models further in the "Debug" mode.

Windows: 
	After opening the project generated by Cmake, you should be able to see 
	3 projects in the "FTRACKER Solution". Right-click on the "FACE_TRACKER" Project
	and choose "Properties". Navigate to "Configuration-Properties->General"
	Change the "Configuration Type" to: "Dynamic Library (.dll)". Here you also 
	should change the "Target Extension" to ".dll". Now you should be able to 
	build the solution. Then, the "FACE_TRACKER.dll" file can be found in 
	"bin/bin/Debug/" directory - this file will be needed in the Unity part.
	
OSX: 
	You have to create a new target in the Project, with the .bundle type. 
	Don't forget to copy all the settings from the target generated by Cmake.
	If you have got a problem with doing this, feel free to contact me.
	
############################################################################
#### Unity Part                                                         ####
############################################################################

There is no setting needed in the Unity project. You only have to copy 3 
files into the root directory of the project: 
	+ face2.tracker from the "model/" directory in the CPP part
	+ trained_svm.yml you have created in the CPP part
	+ FACE_TRACKER.dll you have created in the CPP part

! Plugins are not supported in the FREE version of Unity, you will need a 
  PRO version. Hovewer, there is a simple workaround for Windows users: 
  copy the .dll file into the root directory of the Unity project. There 
  will be a "FACE_TRACKER.dll" file in the Unity Project (That will help
  you locate the place where to copy the .dll), simple replace this with 
  your generated version. This workaround works in v4.X only !

Important note: Sometimes happens (often right at the start of tracking), 
	that the model fitted by FaceTracker will be misslocated.
	In this case the model will also lose the shape, what causes the 
	break-up of the 3D model. To re-initialise the tracker, simple hold 
	your hand in the front of the camera for a second, the FaceTracker will
	correctly re-track your face as soon as you will put your hand away again.
 
Note: Please consider this is not the final version of the project, the 
      "trained_svm.yml" will be re-trained and the 3D Face will be 
	  calibrated more precisely. There are two rigged Face Models in the 
	  Unity project you can switch between - "Holmen advance headrig" and 
	  "holmen face rig". (In case of switching to the second model, also 
	  comments in the .cs files from directory "Assets/Controller/FaceClasses"
	  have to be switched.)
